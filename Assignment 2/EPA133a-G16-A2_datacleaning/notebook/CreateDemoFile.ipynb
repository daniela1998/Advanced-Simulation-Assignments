{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# G16 Code for creating demo data"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 0. Load data"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "print(sys.prefix)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# import data\n",
    "dir = '../data/raw/'\n",
    "filename = 'BMMS_overview.xlsx'\n",
    "df_bridges = pd.read_excel(dir + filename)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#df_bridges.head()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# import data\n",
    "dir = '../data/raw/'\n",
    "filename = '_roads3.csv' # replace this with the interpolated data\n",
    "df_roads = pd.read_csv(dir + filename)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#df_roads.head()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# print shape of dataframes\n",
    "print(df_bridges.shape)\n",
    "print(df_roads.shape)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Remove duplicates from BMMS_overview.xlsx"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_bridges_clean = df_bridges.copy()\n",
    "df_bridges_clean.info()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# add a new colum 'road_lrp' combines 'road' and 'lrp'\n",
    "df_bridges_clean['road_lrp'] = df_bridges_clean['road'] + df_bridges_clean['LRPName']\n",
    "\n",
    "# add a new column 'name_clean' equals to 'name' \n",
    "df_bridges_clean['name_clean'] = df_bridges_clean['name']\n",
    "\n",
    "# add a new column 'road_chainage' equals to 'chainage', but turn float into string, combine 'road' and 'chainage'\n",
    "df_bridges_clean['road_chainage'] = df_bridges_clean['chainage'].astype(str)\n",
    "df_bridges_clean['road_chainage'] = df_bridges_clean['road'] + df_bridges_clean['road_chainage']\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "#df_bridges_clean.head()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# lower the letters \n",
    "df_bridges_clean['name_clean'] = df_bridges_clean['name_clean'].str.lower()\n",
    "\n",
    "# delet space \n",
    "df_bridges_clean['name_clean'] = df_bridges_clean['name_clean'].str.replace(' ', '')\n",
    "\n",
    "# delet hypen\n",
    "df_bridges_clean['name_clean'] = df_bridges_clean['name_clean'].str.replace('-', '')\n",
    "\n",
    "# delet comma\n",
    "df_bridges_clean['name_clean'] = df_bridges_clean['name_clean'].str.replace(',', '')\n",
    "\n",
    "# mark the unknown road name\n",
    "df_bridges_clean.loc[df_bridges_clean['name_clean'] == '.', 'name_clean'] = 'unknown'\n",
    "\n",
    "# delet period \n",
    "df_bridges_clean['name_clean'] = df_bridges_clean['name_clean'].str.replace('.', '')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_bridges_clean.shape"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# delete duplicate in both 'road_lrp' and 'road_chainage' columns\n",
    "df_bridges_clean = df_bridges_clean.drop_duplicates(subset=['road_lrp','chainage'], keep='first')\n",
    "df_bridges_clean.shape"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# replace (r) with (right), (l) with (left) in column 'name_clean'\n",
    "df_bridges_clean.loc[:, 'name_clean'] = df_bridges_clean['name_clean'].str.replace('right', 'r')\n",
    "df_bridges_clean.loc[:, 'name_clean'] = df_bridges_clean['name_clean'].str.replace('left', 'l')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# find the duplicated value in 'road_chainage' column, show the unique values in 'name_clean' column\n",
    "df_bridges_clean[df_bridges_clean.duplicated(subset=['road_chainage'], keep=False)].sort_values(by='road_chainage').name_clean.unique()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Function to filter bridges based on left or right (keep left bridge), and conditions (keep worse condition)\n",
    "def filter_bridges(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Condition priority (higher = worse condition)\n",
    "    condition_priority = {'A': 1, 'B': 2, 'C': 3, 'D': 4}\n",
    "    df['condition_priority'] = df['condition'].map(condition_priority)\n",
    "\n",
    "    # Group by 'chainage'\n",
    "    grouped = df.groupby('road_chainage')\n",
    "\n",
    "    rows_to_keep = []\n",
    "\n",
    "    for _, group in grouped:\n",
    "        if len(group) == 1:  # If only one row exists for this chainage, keep it\n",
    "            rows_to_keep.append(group.index[0])\n",
    "            continue\n",
    "\n",
    "        # Identify left and right bridges\n",
    "        left_bridge = group[group['name_clean'].str.contains('(l)', na=False, regex=False)]\n",
    "        right_bridge = group[group['name_clean'].str.contains('(r)', na=False, regex=False)]\n",
    "\n",
    "        if not left_bridge.empty and not right_bridge.empty:\n",
    "            # If both left and right exist, keep only the left bridge\n",
    "            rows_to_keep.append(left_bridge.index[0])\n",
    "        else: \n",
    "            # If two (r) or two (l) exist, or none of them exist, keep the one with the worst condition\n",
    "            worst_bridge = group.sort_values(by='condition_priority', ascending=False).iloc[0]\n",
    "            rows_to_keep.append(worst_bridge.name)\n",
    "\n",
    "    # Keep only selected rows\n",
    "    return df.loc[rows_to_keep].drop(columns=['condition_priority']).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Apply function\n",
    "df_bridges_clean = filter_bridges(df_bridges_clean)\n",
    "df_bridges_clean.shape"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# check the duplicated value in 'chainage' column\n",
    "df_bridges_clean[df_bridges_clean.duplicated(subset=['road_chainage'], keep=False)].sort_values(by=['road_lrp'])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Remove duplicates from _roads3.csv"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_roads_clean = df_roads.copy()\n",
    "df_roads_clean.info()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# add a new column 'road_chainage' equals to 'chainage', but turn float into string, combine 'road' and 'chainage'\n",
    "df_roads_clean['road_chainage'] = df_roads_clean['chainage'].astype(str)\n",
    "df_roads_clean['road_chainage'] = df_roads_clean['road'] + df_roads_clean['road_chainage']\n",
    "\n",
    "# add a new colum 'road_lrp' combines 'road' and 'lrp'\n",
    "df_roads_clean['road_lrp'] = df_roads_clean['road'] + df_roads_clean['lrp']\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#df_roads_clean.head()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# find the duplicated value in 'road_lrp' column\n",
    "df_roads_clean[df_roads_clean.duplicated(subset=['road_lrp'], keep=False)].sort_values(by='road_lrp')\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# check rows between index 27330 and 27347\n",
    "df_roads_clean.loc[27330:27347]\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# manually change the lrp in row 27331 to 'LRP028', road_lrp to 'Z2002LRP028'\n",
    "df_roads_clean.loc[27331, 'lrp'] = 'LRP028'\n",
    "df_roads_clean.loc[27331, 'road_lrp'] = 'Z2002LRP028'"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# clean the duplicated road_lrp, as all the bridge information come from BMMW_overview.xlsx\n",
    "df_roads_clean = df_roads_clean.drop_duplicates(subset=['road_lrp'], keep='first')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# check the duplicated value in 'road_lrp' column\n",
    "df_roads_clean[df_roads_clean.duplicated(subset=['road_lrp'], keep=False)].sort_values(by='road_lrp')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Combine data from BMMS_overview.xlsx & _roads3.csv"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# change the column names of the bridges dataframe: LRPName -> lrp\n",
    "df_bridges_clean.rename(columns={'LRPName': 'lrp'}, inplace=True)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# add a column named 'model_type' to the df_bridges dataframe and fill it with 'bridge'\n",
    "df_bridges_clean['model_type'] = 'bridge'\n",
    "\n",
    "# add a column named 'model_type' to the df_roads dataframe and fill it with 'link';\n",
    "# but if the last character in the column 'lrp' isn't number, fill it with 'bridge', except for 'S' and 'E'\n",
    "df_roads_clean['model_type'] = 'link'\n",
    "df_roads_clean.loc[df_roads['lrp'].str[-1].str.isnumeric() == False, 'model_type'] = 'bridge'\n",
    "df_roads_clean.loc[df_roads['lrp'].str[-1] == 'S', 'model_type'] = 'link'\n",
    "df_roads_clean.loc[df_roads['lrp'].str[-1] == 'E', 'model_type'] = 'link'\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#df_roads"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# make a copy of the df_bridges dataframe and name it df_bridges_original\n",
    "df_bridges_original = df_bridges_clean.copy()\n",
    "\n",
    "# merge the df_bridges and df_roads dataframes\n",
    "df_concat = pd.concat([df_bridges_clean, df_roads_clean])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#df_concat.head()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# sort the df_concat dataframe, groupedby 'road', by 'chainage'\n",
    "df_concat = df_concat.sort_values(by=['road', 'chainage'])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#df_concat.head()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Build the demo dataframe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# if the 'model_type' is 'bridge' and the 'condition' is NaN, drop the row; Keep the rows with 'model_type' as 'link'\n",
    "df_concat = df_concat[~((df_concat['model_type'] == 'bridge') & (df_concat['condition'].isna())) | (df_concat['model_type'] == 'link')]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize an empty list to store the rows of the new DataFrame\n",
    "new_rows = []\n",
    "\n",
    "# Iterate over each unique road in df_concat\n",
    "for road in df_concat['road'].unique():\n",
    "    road_rows = df_concat[df_concat['road'] == road].reset_index(drop=True)\n",
    "    for i, row in road_rows.iterrows():\n",
    "        if i == 0:\n",
    "            model_type = 'source'\n",
    "        elif i == len(road_rows) - 1:\n",
    "            model_type = 'sink'\n",
    "        else:\n",
    "            model_type = row['model_type']\n",
    "        \n",
    "        length = 0 if i == 0 else row['chainage'] - road_rows.loc[i-1, 'chainage']\n",
    "        new_row = {\n",
    "            'road': row['road'],\n",
    "            'id': f\"{row['road']}_{i}\",\n",
    "            'model_type': model_type,\n",
    "            'name': row['name'],\n",
    "            'lat': row['lat'],\n",
    "            'lon': row['lon'],\n",
    "            'length': length,\n",
    "            'condition': row['condition']\n",
    "        }\n",
    "        new_rows.append(new_row)\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "df_demo = pd.DataFrame(new_rows)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_demo.head()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# print shape of df_demo\n",
    "print(df_demo.shape)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Save demo file as a csv"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# save the df_demo dataframe to a csv file\n",
    "dir = '../data/processed/'\n",
    "filename = 'demo_100.csv'\n",
    "df_demo.to_csv(dir + filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
